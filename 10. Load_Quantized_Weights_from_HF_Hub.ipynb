{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c040d148",
   "metadata": {
    "height": 47
   },
   "source": [
    "# Load The Quantized Weights from Hugging Face Hub\n",
    "It is not efficient to first load the model in its default dtype and then quantize it. In practice, we can maybe quantize the model using a large instance. If we have a big machine we can quantize the model using the machine and then push the quantized weights somewhere on the cloud. And then directly load the model in 8-bit precision or even lower precision on our machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4644bc6b",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from helper import W8A16LinearLayer, replace_linear_with_target_and_quantize, replace_linear_with_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaf5ead",
   "metadata": {
    "height": 64
   },
   "source": [
    "## Memory Efficient Model Loading\n",
    "\n",
    "- Load [facebook/opt-125m](https://huggingface.co/facebook/opt-125m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99fa2528",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_id = \"./models/facebook/opt-125m\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, torch_dtype=torch.bfloat16, low_cpu_mem_usage=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c057796a",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "replace_linear_with_target_and_quantize(model, W8A16LinearLayer, [\"lm_head\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "179d8768",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTForCausalLM(\n",
       "  (model): OPTModel(\n",
       "    (decoder): OPTDecoder(\n",
       "      (embed_tokens): Embedding(50272, 768, padding_idx=1)\n",
       "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 768)\n",
       "      (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): W8A16LinearLayer()\n",
       "            (v_proj): W8A16LinearLayer()\n",
       "            (q_proj): W8A16LinearLayer()\n",
       "            (out_proj): W8A16LinearLayer()\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): W8A16LinearLayer()\n",
       "          (fc2): W8A16LinearLayer()\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50272, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f97731ee",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "quantized_state_dict = model.state_dict()\n",
    "torch.save(quantized_state_dict, \"quantized_state_dict.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af64ead",
   "metadata": {
    "height": 336
   },
   "source": [
    "- You'll need your own Hugging Face username in order for it to run.\n",
    "- You'll add your username in YOUR_HF_USERNAME = \"\"\n",
    "\n",
    "```Python\n",
    "from huggingface_hub import HfApi, create_repo\n",
    "\n",
    "YOUR_HF_USERNAME = \"\"\n",
    "your_repo_id = f\"{YOUR_HF_USERNAME}/opt-125m-quantized-dlai\"\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "# create_repo(your_repo_id)\n",
    "\n",
    "api.upload_file(\n",
    " path_or_fileobj=\"quantized_state_dict.pth\",\n",
    " path_in_repo=\"quantized_state_dict.pth\",\n",
    " repo_id=your_repo_id\n",
    ")\n",
    "```\n",
    "\n",
    "Using this method we can push our quantized weights onto the Hugging Face Hub."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a408ad6",
   "metadata": {
    "height": 30
   },
   "source": [
    "## Load the Model in the Meta Device\n",
    "We will first load the skeleton of the model inorder to get the architecture of the model, after this we just need to replace all the linear layers with the quantized layers withoud quantizing the model since we don't have access to the weights as all the weights are in the meta device, means they are not getting initialized. Then we cal call the state_dict which will asign the correct weights. And in this way we save our CPU memory as we directly load the quantized version of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b53f0cb",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "from transformers import OPTForCausalLM, AutoTokenizer, AutoConfig\n",
    "\n",
    "model_id = \"./models/facebook/opt-125m\"\n",
    "config = AutoConfig.from_pretrained(model_id)\n",
    "\n",
    "with torch.device(\"meta\"):\n",
    "  model = OPTForCausalLM(config)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcbcc15-453d-42bd-bb08-8a5dbd37ef1e",
   "metadata": {},
   "source": [
    "Here we have loaded the **config** of the model to get the detailed architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b7f7568",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(50272, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(2050, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(3072, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(3072,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 3072), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(3072, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(3072,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 3072), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(3072, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(3072,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 3072), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(3072, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(3072,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 3072), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(3072, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(3072,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 3072), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(3072, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(3072,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 3072), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(3072, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(3072,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 3072), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(3072, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(3072,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 3072), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(3072, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(3072,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 3072), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(3072, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(3072,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 3072), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(3072, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(3072,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 3072), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(3072, 768), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(3072,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768, 3072), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor(..., device='meta', size=(768,), requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "  print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9507ae-99a3-448a-9569-6b80bb1c795e",
   "metadata": {},
   "source": [
    "We have loaded our model but the tensors are not initialized at all. So we have bunch of meta tensors that don't take any RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bde3b4ce",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTForCausalLM(\n",
       "  (model): OPTModel(\n",
       "    (decoder): OPTDecoder(\n",
       "      (embed_tokens): Embedding(50272, 768, padding_idx=1)\n",
       "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 768)\n",
       "      (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50272, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75a45d09",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "replace_linear_with_target(model, W8A16LinearLayer, [\"lm_head\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa38c755",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTForCausalLM(\n",
       "  (model): OPTModel(\n",
       "    (decoder): OPTDecoder(\n",
       "      (embed_tokens): Embedding(50272, 768, padding_idx=1)\n",
       "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 768)\n",
       "      (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): W8A16LinearLayer()\n",
       "            (v_proj): W8A16LinearLayer()\n",
       "            (q_proj): W8A16LinearLayer()\n",
       "            (out_proj): W8A16LinearLayer()\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): W8A16LinearLayer()\n",
       "          (fc2): W8A16LinearLayer()\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50272, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c187ade-3d20-4969-a214-af04d7b3d488",
   "metadata": {},
   "source": [
    "After replacing the linear layers we will load the state dicts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bfd7706",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "state_dict_cache_path = hf_hub_download(\n",
    "    \"ybelkada/opt-125m-quantized-dlai\",\n",
    "    \"quantized_state_dict.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4e52136",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "state_dict = torch.load(state_dict_cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d3da3dd",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict, strict=True, assign=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edb55b1a",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Hello today I am a student at the University of California, San Diego.\\nI am a student at the University of California, San Diego.\\nI am a student at the University of California, San Diego.\\n'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "pipe(\"Hello today I am\", max_new_tokens=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12979ce3",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Hello today I am giving a course about the history of the world and the history of the'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "pipe(\"Hello today I am giving a course about\", max_new_tokens=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96162fbe",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
