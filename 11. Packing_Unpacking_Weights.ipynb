{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights Packing\n",
    "Assume we want to quantize our model in 4-bit precision, and we want to store the weights in a\n",
    "torch tensor. So ideally we want to create a tensor with some values and pass `dtype=torch.int4`.\n",
    "But the problem is there is no native support for 4-bit weights in PyTorch.\n",
    "```python\n",
    "import torch\n",
    "tensor = torch.tensor([0,1], dtype=torch.int4) # is not supported!\n",
    "```\n",
    "The only possible solution is instead of saving the tensor in 4-bit we have to save it in 8-bit\n",
    "as currently it's the dtype with smallest precision that is available in PyTorch. So in practice\n",
    "we need to save the tensor in 8-bit precision. But this will overhead for large models therefore if we go for native approach, means if we store the 4-bit weights in an 8-bit tensor, \n",
    "there will be no point quantizing the model into 4-bit because all the parameters will be stored in 8-bit precision. So for that we need to pack the 4-bit weights into 8-bit tensor.\n",
    "\n",
    "## How does packing works?\n",
    "Consider the tensor given bbelow that stores 4 values that can be represented in 2-bit precision, but stored in 8-bit.\n",
    "```python\n",
    "import torch\n",
    "unpacked_tensor = torch.tensor([1, 0, 3, 2], dtype=torch.int8)\n",
    "```\n",
    "Currently this tensor is stored as [00000001  00000000  00000011  00000010]. This is not really optimal as we need to allocate 4 times 8-bit terms of memory in order to store weights that can be encoded only in 2-bit.<br>\n",
    "To solve this we can \"pack\" all these data points into a single 8-bit tensor as [10110001]-->(10,11,00,01). This value in unit8 will end up being 177.\n",
    "```python\n",
    "packed_tensor = torch.tensor([177], dtype=torch.int8)\n",
    "```\n",
    "#### Advantages:\n",
    "- It reflects the \"true\" memory footprint of the quantized weights\n",
    "#### Disadvantages:\n",
    "- The unpacked tensors need to be a shape with a multiple of 8//nbits\n",
    "- It needs to unpack before performing an operation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4UNB9a6jCkU"
   },
   "source": [
    "# Packing 2-bit Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "# Example Tensor: [1, 0, 3, 2]\n",
    "    # 1 0 3 2 - 01 00 11 10\n",
    "\n",
    "    # Starting point of packed int8 Tensor\n",
    "    # [0000 0000]\n",
    "    \n",
    "    ##### First Iteration Start:\n",
    "    # packed int8 Tensor State: [0000 0000]\n",
    "    # 1 = 0000 0001\n",
    "    # 0000 0001\n",
    "    # No left shifts in the First Iteration\n",
    "    # After bit-wise OR operation between 0000 0000 and 0000 0001:\n",
    "    # packed int8 Tensor State: 0000 0001\n",
    "    ##### First Iteration End\n",
    "\n",
    "    ##### Second Iteration Start:\n",
    "    # packed int8 Tensor State: [0000 0001]\n",
    "    # 0 = 0000 0000\n",
    "    # 0000 0000\n",
    "    # 2 left shifts:\n",
    "    # [0000 0000] (1 shift)-> 0000 0000 (2 shift)-> 0000 0000\n",
    "    # After bit-wise OR operation between 0000 0001 and 0000 0000:\n",
    "    # packed int8 Tensor State: 0000 0001\n",
    "    ##### Second Iteration End\n",
    "\n",
    "    ##### Third Iteration Start:\n",
    "    # packed int8 Tensor State: [0000 0001]\n",
    "    # 3 = 0000 0011\n",
    "    # 0000 0011\n",
    "    # 4 left shifts:\n",
    "    # [0000 0011] (1 shift)-> 0000 0110 (2 shift)-> 0000 1100\n",
    "    # 0000 1100 (3 shift)-> 0001 1000 (4 shift)-> 0011 0000\n",
    "    # After bit-wise OR operation between 0000 0001 and 0011 0000:\n",
    "    # packed int8 Tensor State: 0011 0001\n",
    "    ##### Third Iteration End\n",
    "\n",
    "    ##### Fourth Iteration Start:\n",
    "    # packed int8 Tensor State: [0011 0001]\n",
    "    # 2 = 0000 0010\n",
    "    # 0000 0010\n",
    "    # 6 left shifts:\n",
    "    # [0000 0010] (1 shift)-> 0000 0100 (2 shift)-> 0000 1000\n",
    "    # 0000 1000 (3 shift)-> 0001 0000 (4 shift)-> 0010 0000\n",
    "    # 0010 0000 (5 shift)-> 0100 0000 (6 shift)-> 1000 0000\n",
    "    # After bit-wise OR operation between 0011 0001 and 1000 0000:\n",
    "    # packed int8 Tensor State: 1011 0001\n",
    "    ##### Fourth Iteration End\n",
    "    \n",
    "    # Final packed int8 Tensor State: [1011 0001]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 218,
     "status": "ok",
     "timestamp": 1705676413805,
     "user": {
      "displayName": "Younes Belkada",
      "userId": "15414910276690549281"
     },
     "user_tz": 0
    },
    "height": 540,
    "id": "ErbmOljngvnC"
   },
   "outputs": [],
   "source": [
    "def pack_weights(uint8tensor, bits):\n",
    "    if uint8tensor.shape[0] * bits % 8 != 0:\n",
    "        raise ValueError(f\"The input shape needs to be a mutiple \\\n",
    "        of {8 / bits} - got {uint8tensor.shape[0]}\")\n",
    "\n",
    "    num_values = uint8tensor.shape[0] * bits // 8\n",
    "\n",
    "    num_steps = 8 // bits # ----> 4\n",
    "\n",
    "    unpacked_idx = 0\n",
    "\n",
    "    packed_tensor = torch.zeros((num_values), dtype=torch.uint8)\n",
    "\n",
    "    # 1 0 3 2 - 01 00 11 10 --> for this each two bits we will retrieve the corresponding value \n",
    "    \n",
    "    # [0000 0000] -> 0000 0001 ==== packed_tensor -> unpacked_tensor (hift these values on left by bits*j)\n",
    "\n",
    "    # 0000 0001 --> result after bitwise OR operation between [0000 0000] and [0000 0001] \n",
    "\n",
    "    # 0000 0000 -> 0000 0000\n",
    "\n",
    "    # 0000 0000 --> result after bitwise OR operation between [0000 0001] and [0000 0000]\n",
    "\n",
    "    # 0000 0011 - 0011 0000 - 0011 0001 --> shifting by 4 bits\n",
    "\n",
    "    # 1011 0001 --> shfiting by 6 bits\n",
    "    \n",
    "    for i in range(num_values):\n",
    "        for j in range(num_steps):\n",
    "            packed_tensor[i] |= uint8tensor[unpacked_idx] << (bits * j)\n",
    "            unpacked_idx += 1\n",
    "    return packed_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "unpacked_tensor = torch.tensor([1, 0, 3, 2], dtype=torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 214,
     "status": "ok",
     "timestamp": 1705676415692,
     "user": {
      "displayName": "Younes Belkada",
      "userId": "15414910276690549281"
     },
     "user_tz": 0
    },
    "height": 30,
    "id": "zcLwmPr1Fdrg",
    "outputId": "f50ccb6b-8ec4-47dc-91c1-bc70db8aafa8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([177], dtype=torch.uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pack_weights(unpacked_tensor, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "unpacked_tensor = torch.tensor([1, 0, 3, 2, 3, 3, 3, 3], dtype=torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([177, 255], dtype=torch.uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pack_weights(unpacked_tensor, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "height": 30
   },
   "source": [
    "## Unpacking 2-Bit Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "# Example Tensor: [10110001]\n",
    "    # Which was Originally: 1 0 3 2 - 01 00 11 10\n",
    "\n",
    "    # Starting point of unpacked Tensor\n",
    "    # [00000000 00000000 00000000 00000000]\n",
    "    \n",
    "    ##### First Iteration Start:\n",
    "    # packed int8 Tensor: [10110001]\n",
    "    # You want to extract 01 from [101100 01]\n",
    "    # No right shifts in the First Iteration\n",
    "    # After bit-wise OR operation between 00000000 and 10110001:\n",
    "    # [10110001 00000000 00000000 00000000]\n",
    "    # unpacked Tensor state: [10110001 00000000 00000000 00000000]\n",
    "    ##### First Iteration End\n",
    "\n",
    "    ##### Second Iteration Start:\n",
    "    # packed int8 Tensor: [10110001]\n",
    "    # You want to extract 00 from [1011 00 01]\n",
    "    # 2 right shifts:\n",
    "    # [10110001] (1 shift)-> 01011000 (2 shift)-> 00101100\n",
    "    # After bit-wise OR operation between 00000000 and 00101100:\n",
    "    # [10110001 00101100 00000000 00000000]\n",
    "    # unpacked Tensor state: [10110001 00101100 00000000 00000000]\n",
    "    ##### Second Iteration End\n",
    "\n",
    "    ##### Third Iteration Start:\n",
    "    # packed int8 Tensor: [10110001]\n",
    "    # You want to extract 11 from [10 11 0001]\n",
    "    # 4 right shifts:\n",
    "    # [10110001] (1 shift)-> 01011000 (2 shift)-> 00101100\n",
    "    # 00101100 (3 shift)-> 00010110 (4 shift)-> 00001011\n",
    "    # After bit-wise OR operation between 00000000 and 00001011:\n",
    "    # [10110001 00101100 00001011 00000000]\n",
    "    # unpacked Tensor state: [10110001 00101100 00001011 00000000]\n",
    "    ##### Third Iteration End\n",
    "\n",
    "    ##### Fourth Iteration Start:\n",
    "    # packed int8 Tensor: [10110001]\n",
    "    # You want to extract 10 from [10 110001]\n",
    "    # 6 right shifts:\n",
    "    # [10110001] (1 shift)-> 01011000 (2 shift)-> 00101100\n",
    "    # 00101100 (3 shift)-> 00010110 (4 shift)-> 00001011\n",
    "    # 00001011 (5 shift)-> 00000101 (6 shift)-> 00000010\n",
    "    # After bit-wise OR operation between 00000000 and 00000010:\n",
    "    # [10110001 00101100 00001011 00000010]\n",
    "    # unpacked Tensor state: [10110001 00101100 00001011 00000010]\n",
    "    ##### Fourth Iteration End\n",
    "    \n",
    "    # Last step: Perform masking (bit-wise AND operation)\n",
    "    # Mask: 00000011\n",
    "    # Bit-wise AND operation between \n",
    "    # unpacked Tensor and 00000011\n",
    "    # [10110001 00101100 00001011 00000010] <- unpacked tensor\n",
    "    # [00000011 00000011 00000011 00000011] <- Mask\n",
    "    # [00000001 00000000 00000011 00000010] <- Result\n",
    "\n",
    "    # Final\n",
    "    # unpacked Tensor state: [00000001 00000000 00000011 00000010]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_weights(uint8tensor, bits):\n",
    "    num_values = uint8tensor.shape[0] * 8 // bits\n",
    "\n",
    "    num_steps = 8 // bits\n",
    "\n",
    "    unpacked_tensor = torch.zeros((num_values), dtype=torch.uint8)\n",
    "\n",
    "    unpacked_idx = 0\n",
    "\n",
    "    # 1 0 3 2 - 01 00 11 10\n",
    "\n",
    "    # [00000000 00000000 00000000 00000000]\n",
    "    # [10110001 00101100 00001011 00000010]\n",
    "    # [00000001 00000000 00000011 00000010]\n",
    "\n",
    "    # 10110001\n",
    "    # 00000011\n",
    "    \n",
    "    # 00000001\n",
    "\n",
    "    # 1: [10110001]\n",
    "    # 2: [00101100]\n",
    "    # 3: [00001011]\n",
    "\n",
    "    mask = 2 ** bits - 1\n",
    "\n",
    "    for i in range(uint8tensor.shape[0]):\n",
    "        for j in range(num_steps):\n",
    "            unpacked_tensor[unpacked_idx] |= uint8tensor[i] >> (bits * j)\n",
    "            unpacked_idx += 1\n",
    "\n",
    "    unpacked_tensor &= mask\n",
    "    return unpacked_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpacked_tensor = torch.tensor([177, 255], dtype=torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 3, 2, 3, 3, 3, 3], dtype=torch.uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer should be: torch.tensor([1, 0, 3, 2, 3, 3, 3, 3]\n",
    "unpack_weights(unpacked_tensor, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPkr3WbwaCNWYoK5KkH4mJ5",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
